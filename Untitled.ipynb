{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4177eafe-44cd-44f2-bfc0-18f55c26b677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:05\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.17.0-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (3.5.1)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Requirement already satisfied: jinja2 in /home/azki/.local/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 KB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/azki/.local/lib/python3.10/site-packages (from torch) (4.9.0)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch) (3.6.0)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting triton==2.2.0\n",
      "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch) (1.9)\n",
      "Collecting nvidia-nccl-cu12==2.19.3\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:05\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-nvjitlink-cu12\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/lib/python3/dist-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: requests in /home/azki/.local/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->torchvision) (1.26.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/azki/.local/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision) (2020.6.20)\n",
      "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
      "Successfully installed fsspec-2024.2.0 networkx-3.2.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 torch-2.2.0 torchvision-0.17.0 triton-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16425d85-7edc-4661-ba66-67f34ab725f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Using downloaded and verified file: ./data/MNIST/raw/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Using downloaded and verified file: ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Using downloaded and verified file: ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Using downloaded and verified file: ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a492d3-93ae-4adb-bc82-f88e0c5c9c29",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8f31128-41ba-4090-877b-ee82201b845b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial model: SimpleCNN(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n",
      "Expanded model: SimpleCNN(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=1024, out_features=15, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, input_channels=3, initial_output_neurons=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc = nn.Linear(64 * 4 * 4, initial_output_neurons)  # Initial FC layer\n",
    "        self.output_neurons = initial_output_neurons\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        x = F.relu(self.fc(x))\n",
    "        return x\n",
    "\n",
    "    def expand_fc_layer(self, additional_neurons):\n",
    "        # Expand the FC layer by adding more neurons\n",
    "        current_weight = self.fc.weight.data\n",
    "        current_bias = self.fc.bias.data\n",
    "        new_weight = torch.cat([current_weight, torch.zeros(additional_neurons, current_weight.shape[1])], dim=0)\n",
    "        new_bias = torch.cat([current_bias, torch.zeros(additional_neurons)], dim=0)\n",
    "        self.fc = nn.Linear(self.fc.in_features, self.fc.out_features + additional_neurons)\n",
    "        self.fc.weight.data = new_weight\n",
    "        self.fc.bias.data = new_bias\n",
    "        self.output_neurons += additional_neurons\n",
    "\n",
    "# Example usage\n",
    "model = SimpleCNN(input_channels=3, initial_output_neurons=10)\n",
    "print(\"Initial model:\", model)\n",
    "\n",
    "# When encountering new classes during incremental learning\n",
    "additional_neurons = 5  # Number of new neurons to add\n",
    "model.expand_fc_layer(additional_neurons)\n",
    "print(\"Expanded model:\", model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df46c1ef-bb8f-4bc4-9f17-bada334afeb1",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62aca5a7-7fed-4e19-ade6-abd1927e71bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in /home/azki/.local/lib/python3.10/site-packages (4.66.2)\n",
      "Collecting lmdb\n",
      "  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 KB\u001b[0m \u001b[31m710.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m646.4 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lmdb\n",
      "Successfully installed lmdb-1.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm lmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8243604f-d51a-45b5-858a-7666ff38f9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms, utils\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from vqvae import VQVAE\n",
    "from scheduler import CycleScheduler\n",
    "import distributed as dist\n",
    "\n",
    "\n",
    "def train(epoch, loader, model, optimizer, scheduler, device):\n",
    "    if dist.is_primary():\n",
    "        loader = tqdm(loader)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    latent_loss_weight = 0.25\n",
    "    sample_size = 25\n",
    "\n",
    "    mse_sum = 0\n",
    "    mse_n = 0\n",
    "\n",
    "    for i, (img, label) in enumerate(loader):\n",
    "        model.zero_grad()\n",
    "\n",
    "        img = img.to(device)\n",
    "\n",
    "        out, latent_loss = model(img)\n",
    "        recon_loss = criterion(out, img)\n",
    "        latent_loss = latent_loss.mean()\n",
    "        loss = recon_loss + latent_loss_weight * latent_loss\n",
    "        loss.backward()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        optimizer.step()\n",
    "\n",
    "        part_mse_sum = recon_loss.item() * img.shape[0]\n",
    "        part_mse_n = img.shape[0]\n",
    "        comm = {\"mse_sum\": part_mse_sum, \"mse_n\": part_mse_n}\n",
    "        comm = dist.all_gather(comm)\n",
    "\n",
    "        for part in comm:\n",
    "            mse_sum += part[\"mse_sum\"]\n",
    "            mse_n += part[\"mse_n\"]\n",
    "\n",
    "        if dist.is_primary():\n",
    "            lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "            loader.set_description(\n",
    "                (\n",
    "                    f\"epoch: {epoch + 1}; mse: {recon_loss.item():.5f}; \"\n",
    "                    f\"latent: {latent_loss.item():.3f}; avg mse: {mse_sum / mse_n:.5f}; \"\n",
    "                    f\"lr: {lr:.5f}\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                model.eval()\n",
    "\n",
    "                sample = img[:sample_size]\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    out, _ = model(sample)\n",
    "\n",
    "                utils.save_image(\n",
    "                    torch.cat([sample, out], 0),\n",
    "                    f\"sample/{str(epoch + 1).zfill(5)}_{str(i).zfill(5)}.png\",\n",
    "                    nrow=sample_size,\n",
    "                    normalize=True,\n",
    "                    range=(-1, 1),\n",
    "                )\n",
    "\n",
    "                model.train()\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    device = \"cuda\"\n",
    "\n",
    "    args.distributed = dist.get_world_size() > 1\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(args.size),\n",
    "            transforms.CenterCrop(args.size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    dataset = datasets.ImageFolder(args.path, transform=transform)\n",
    "    sampler = dist.data_sampler(dataset, shuffle=True, distributed=args.distributed)\n",
    "    loader = DataLoader(\n",
    "        dataset, batch_size=128 // args.n_gpu, sampler=sampler, num_workers=2\n",
    "    )\n",
    "\n",
    "    model = VQVAE().to(device)\n",
    "\n",
    "    if args.distributed:\n",
    "        model = nn.parallel.DistributedDataParallel(\n",
    "            model,\n",
    "            device_ids=[dist.get_local_rank()],\n",
    "            output_device=dist.get_local_rank(),\n",
    "        )\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "    scheduler = None\n",
    "    if args.sched == \"cycle\":\n",
    "        scheduler = CycleScheduler(\n",
    "            optimizer,\n",
    "            args.lr,\n",
    "            n_iter=len(loader) * args.epoch,\n",
    "            momentum=None,\n",
    "            warmup_proportion=0.05,\n",
    "        )\n",
    "\n",
    "    for i in range(args.epoch):\n",
    "        train(i, loader, model, optimizer, scheduler, device)\n",
    "\n",
    "        if dist.is_primary():\n",
    "            torch.save(model.state_dict(), f\"checkpoint/vqvae_{str(i + 1).zfill(3)}.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3b5f97-91d6-4f7d-82d5-67eb50ebe523",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--n_gpu\", type=int, default=1)\n",
    "\n",
    "    port = (\n",
    "        2 ** 15\n",
    "        + 2 ** 14\n",
    "        + hash(os.getuid() if sys.platform != \"win32\" else 1) % 2 ** 14\n",
    "    )\n",
    "    parser.add_argument(\"--dist_url\", default=f\"tcp://127.0.0.1:{port}\")\n",
    "\n",
    "    parser.add_argument(\"--size\", type=int, default=256)\n",
    "    parser.add_argument(\"--epoch\", type=int, default=560)\n",
    "    parser.add_argument(\"--lr\", type=float, default=3e-4)\n",
    "    parser.add_argument(\"--sched\", type=str)\n",
    "    parser.add_argument(\"path\", type=str)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    print(args)\n",
    "\n",
    "    dist.launch(main, args.n_gpu, 1, 0, args.dist_url, args=(args,))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
